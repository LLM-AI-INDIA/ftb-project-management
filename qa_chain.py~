import pandas as pd
from langchain_groq import ChatGroq
from langchain.chains import RetrievalQA
from langchain.text_splitter import CharacterTextSplitter
from langchain.docstore.document import Document
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings

# Load CSVs and convert to Documents
def load_csvs(csv_paths):
    docs = []
    for path in csv_paths:
        df = pd.read_csv(path)
        for _, row in df.iterrows():
            content = " | ".join([f"{col}: {row[col]}" for col in df.columns if not pd.isna(row[col])])
            docs.append(Document(page_content=content))
    return docs

def build_qa(csv_paths):
    # Step 1: Load documents
    documents = load_csvs(csv_paths)

    # Step 2: Split into chunks
    splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_documents(documents)

    # Step 3: Embed + Store
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vectorstore = FAISS.from_documents(chunks, embeddings)

    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

    # Step 4: Groq LLM
    llm = ChatGroq(model="llama-3.1-8b-instant")

    # Step 5: RetrievalQA
    qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)
    return qa_chain
